# Decision Tree: M4 Development with AMZL Data Discovery
## Version: V101-V120 (Data Access & Reality Alignment)

---

## Previous Nodes (V1-V100)
[Physics investigation, batch processing discovery, hourly data limitations, M2 revelation]

---

## Node 101: AMZL Team Engagement
**Decision**: Engage AMZL team for data access
**Context**: Need 5-minute granularity for physics-based M4
**Action**: Asked for specific columns, tables, granularity
**Learning**: They're working on access to Mercury and Logistics dashboards
```python
# THOUGHT: AMZL might have better data than hourly CSVs
# DISCOVERY: Mercury has "dwelling5m" - 5-minute data exists!
# ACTION: Pursue Mercury data access
```

## Node 102: SQL Query Discovery
**Decision**: Find how we generated the 30-station data
**Finding**: Located `instation_container_levels_v3.sql`
**Tables**:
- `hb_na_heisenbergrefinedobjects.d_perfectmile_shipment_status_history`
- `hb_na_heisenbergrefinedobjects.d_perfectmile_instation_events`
- `hb_na_heisenbergrefinedobjects.package_system_shadow_universe`
```sql
# CRITICAL: Query uses :time_interval_minutes parameter
# CURRENT: Set to 60 (hourly)
# POTENTIAL: Can change to 5 for 5-minute data!
# BLOCKER: export_data.sh script not found
```

## Node 103: Mercury Dashboard Discovery
**Decision**: Investigate Mercury monitoring capabilities
**URL Pattern**: `monitoringTemplate=SSD&dwellType=dwelling5m`
**Revelation**: 5-minute dwell monitoring already exists in production!
```python
# BREAKTHROUGH: Infrastructure for 5-min data exists
# IMPLICATION: M4 can do real physics if we get access
# QUESTION: How to programmatically access this data?
```

## Node 104: Station Dashboard Access
**Decision**: Understand Logistics dashboard capabilities
**URL**: `logistics.amazon.com/station/dashboard/overviewv2`
**Purpose**: Real-time station metrics for operations
```python
# POTENTIAL: Real-time queue depths, throughput rates
# NEED: API or export capability
# USE CASE: M4 real-time monitoring
```

## Node 105: Data Requirements Crystallization
**Decision**: Define exact data needs for M4
**Essential Requirements**:
1. Timestamp ≤ 5 minutes
2. Node metrics: queue_depth, inflow, outflow
3. Edge flows: source→destination transfers (CRITICAL)
4. Capacity indicators: workers, equipment_status
5. Event markers: disruptions, maintenance
```python
# MINIMUM VIABLE: 5-min node metrics
# IDEAL: Event-level with edge flows
# BLOCKER: No edge flow visibility in current data
```

## Node 106: The Export Script Mystery
**Decision**: Search for export_data.sh
**Result**: Script not found in current workspace
**Implication**: Need alternative data extraction method
```python
# MISSING: export_data.sh referenced in SQL comments
# WORKAROUND: Direct database query via Python/Athena
# ACTION: Ask AMZL team for access method
```

## Node 107: Station List Confirmation
**Decision**: Confirm which stations we're working with
**Primary**: DAE1 (all physics testing)
**Full Set**: 30 stations (DAE1, DAE3, DAE7, DBC3, DBO9...)
**Date Range**: July 18 - August 18, 2025 (synthetic/future dates)
```python
# QUESTION: Are these synthetic test dates?
# NEED: Mapping to real data periods
# CONCERN: Future timestamps suggest test data
```

## Node 108: The Granularity Question
**Decision**: Verify what granularity is actually available
**Current**: 60-minute aggregations in CSVs
**Mercury**: 5-minute dwell monitoring confirmed
**Unknown**: Can we query Heisenberg tables at 5-min?
```python
# TEST NEEDED: Run SQL with time_interval_minutes=5
# VALIDATION: Should get 12x more data points
# RISK: Database might not support sub-hourly
```

## Node 109: M4 Design Pivot
**Decision**: Design M4 based on data availability
**If 5-min data available**:
```python
M4_with_5min = {
    'type': 'Physics-based monitor',
    'monitors': ['Conservation violations', 'Bottlenecks', 'Flow constraints'],
    'alerts': 'Real anomalies, not patterns'
}
```
**If stuck with hourly**:
```python
M4_hourly_only = {
    'type': 'Statistical pattern detector',
    'monitors': ['Deviations from typical', 'Trend changes'],
    'alerts': 'Statistical anomalies only'
}
```

## Node 110: Critical Data Gaps
**Decision**: Identify what's missing for physics M4
**Gap 1**: No edge flows between nodes
**Gap 2**: No capacity/worker data
**Gap 3**: No event/disruption markers
**Impact**: M3 parameters underdetermined, M4 can't identify true bottlenecks
```python
# WITHOUT EDGE FLOWS: Can't determine routing splits
# WITHOUT CAPACITY: Can't distinguish low demand vs bottleneck
# WITHOUT EVENTS: Can't contextualize anomalies
```

## Node 111: The Demo Preparation
**Decision**: Prepare for tomorrow's M1 demo
**Key Questions**:
1. What data granularity does M1 actually extract?
2. How does M3 handle parameter uncertainty?
3. What assumptions is M3 making?
**Strategy**: Use AMZL prototype to show potential, document limitations
```python
# SHOW: What's possible with 5-min data (AMZL)
# DOCUMENT: Degradation with hourly data
# ASK: Investment in better data infrastructure
```

## Node 112: The Communication Challenge
**Decision**: Frame M4 capabilities honestly
**Message**: "M4 quality directly depends on data granularity"
**Risk**: Prototype (AMZL) >> Production (hourly) capabilities
**Mitigation**: Clear documentation of data dependencies

## Node 113: Today's Progress Summary
**Achievements**:
- Found SQL query structure
- Discovered Mercury 5-min monitoring exists
- Defined exact data requirements
- Identified critical gaps (edge flows, capacity)
**Blockers**:
- No export_data.sh script
- No direct database access yet
- Edge flows not available
- M3 parameters remain underdetermined

---

## Meta-Learning from V101-V113:

### Key Discoveries:
1. **5-minute data exists** in Mercury monitoring
2. **SQL supports variable granularity** via time_interval_minutes
3. **Edge flows are critical** but currently unavailable
4. **Export mechanism unclear** without script

### Critical Decisions Needed:
1. How to access Mercury 5-min data programmatically?
2. Can we query Heisenberg tables directly?
3. How to handle M3 without edge flows?
4. What to demo if only hourly data available?

### The Path Forward:
1. **Tomorrow AM**: Get database access confirmation
2. **During Demo**: Ask about M1 data extraction details
3. **With AMZL Team**: Push for Mercury API access
4. **For M4**: Build two versions (5-min physics vs hourly statistics)

---

## Next Nodes (V114+):
- [ ] M1 demo insights and revelations
- [ ] Database access success/failure
- [ ] M4 prototype based on actual data
- [ ] Production deployment reality